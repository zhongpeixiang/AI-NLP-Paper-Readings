# NLP - Sentiment Analysis
|Paper|Conference|Remarks
|--|--|--|
|[Twitter Sentiment Classification using Distant Supervision](https://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf)|N.A. 2009|Introduces a novel approach for automatically classifying the sentiment of Twitter messages using distant supervised learning.|
|[Convolutional Neural Networks for Sentence Classification](https://www.aclweb.org/anthology/D14-1181)|EMNLP 2014|Show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks in the sentence classification task.|
|[Comparing and Combining Sentiment Analysis Methods](https://arxiv.org/abs/1406.0032)|Arxiv 2014|1. Present comparisons of eight popular sentiment analysis methods in terms of coverage (i.e., the fraction of messages whose sentiment is identified) and agreement (i.e., the fraction of identified sentiments that are in tune with ground truth). 2. Develop a new method that combines existing approaches, providing the best coverage results and competitive agreement. 3. Present a free Web service called iFeel, which provides an open API for accessing and comparing results across different sentiment methods for a given text.|
|[Sentiment analysis algorithms and applications: A survey](https://www.sciencedirect.com/science/article/pii/S2090447914000550)|Ain Shams Engineering Journal 2014|1. Give nearly full image of SA techniques and the related fields with brief details. 2. Provide sophisticated categorizations of a large number of recent articles and the illustration of the recent trend of research in the sentiment analysis and its related areas.|
|[Sentiment Analysis: Detecting Valence, Emotions, and Other Affectual States from Text](https://www.sciencedirect.com/science/article/pii/B9780081005088000096)|Emotion Measurement 2015|1. Summarize the diverse landscape of tasks and applications associated with sentiment analysis. 2. Outline key challenges stemming from the complexity and subtlety of language use, the prevalence of creative and non-standard language, and the lack of paralinguistic information, such as tone and stress markers. 3. Describe automatic systems and datasets commonly used in sentiment analysis. 4. Summarize several manual and automatic approaches to creating valence- and emotion-association lexicons. 5. Discuss preliminary approaches for sentiment composition (how smaller units of text combine to express sentiment) and approaches for detecting sentiment in figurative and metaphoric language|
|[A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification](https://arxiv.org/pdf/1510.03820)|Arxiv 2015|1. Conduct a sensitivity analysis of one-layer CNNs to explore the effect of architecture components on model performance. 2. Distinguish between important and comparatively inconsequential design decisions for sentence classification. 3. Derive practical advice from our extensive empirical results for those interested in getting the most out of CNNs for sentence classification in real world settings|
|[Sentiment Analysis: Detecting Valence, Emotions, and Other Affectual States from Text](https://www.sciencedirect.com/science/article/pii/B9780081005088000096)|Emotion Measurement 2016|1.  Sentiment analysis refers to determining ones' attitude towards a particular target or topic. 2. Osgood et al. (1957) showed three most prominent dimensions of meaning are evaluation (good-bad), potency (strong-weak) and activity (active-passive), or EPA form in short. Another popular form is valence, arousal and dominance, or PAD form by Russell (1980). 3. Sentiment analysis has wide-ranging applications in healthcare, politics, brand management, education, etc.|
|[Sentiment analysis leveraging emotions and word embeddings](https://www.sciencedirect.com/science/article/pii/S095741741630584X)|Expert Systems With Applications 2016|1. Proposes a fast, flexible, generic methodology for sentiment detection out of textual snippets which express people’s opinions in different languages. 2. Adopts a machine learning approach with which textual documents are represented by vectors and are used for training a polarity classification model. 3. The competence of these feature representations for the sentiment classification task is assessed|
|[Linguistically Regularized LSTM for Sentiment Classification](http://www.aclweb.org/anthology/P17-1154)|ACL 2017| 1. A simple model trained with sentence-level annotations which attempt to model the linguistic role of sentiment lexicons, negation words and intensity words|
|[EmoNet: Fine-Grained Emotion Detection with Gated Recurrent Neural Networks](http://www.aclweb.org/anthology/P17-1067)|ACL 2017| 1. Create a very large dataset of size 1.6 million tweets for 24 fine-grained emotions. 2. Build a very deep GRU model for sentiment classification with state of the art result.|
|[Context-Dependent Sentiment Analysis in User-Generated Videos](http://www.aclweb.org/anthology/P17-1081)|ACL 2017| Propose a LSTM-based model that enables utterances to capture contextual information from their surroundings in multimodal video analysis|
|[Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm](https://arxiv.org/pdf/1708.00524)|EMNLP 2017| 1. Extend the distant supervision to a more diverse set of noisy labels, using a dataset of 1246 million tweets containing one of 64 common emojis to learn richer representations. 2. Obtain state-of-the-art performance on 8 benchmark datasets within sentiment, emotion and sarcasm detection using a single pretrained model.|
|[EMOBANK: Studying the Impact of Annotation Perspective and Representation Format on Dimensional Emotion Analysis](http://aclweb.org/anthology/E17-2092)|EACL 2017| 1. A corpus of 10k English sentences with VAD annotations. 2. A subset of 1200 English sentences with both VAD and Ekman six basic emotion ratings. 3. Both reader and writer perspectives. 4. Close-to-human performance for mapping between dimensional and categorical formats|
|[Attention Modeling for Targeted Sentiment](http://leoncrashcode.github.io/Documents/EACL2017.pdf)|EACL 2017| A vanilla LSTM model is used to induce an attention value of the whole sentence. The model is further extended to differentiate left and right contexts given a certain target following previous work|
|[Attention-Based LSTM for Target-Dependent Sentiment Classification](http://leoncrashcode.github.io/Documents/EACL2017.pdf)|EACL 2017| Learns the alignment between the target entities and the most distinguishing features.|
|[Deep LSTM with Attention for Message-level and Topic-based Sentiment Analysis](http://aclweb.org/anthology/S17-2126)|SemEval 2017| 1. Two-layers LSTM with attention, on top of word embeddings. 2. Present a text processing tool for twitter dataset|
|[Exploring Emotion Embedding and the Dimensional Model of Emotion ’ s Predictive Power in Sentiment by](https://pdfs.semanticscholar.org/abee/3583b3547175a829965f4756ce01d491dec1.pdf)|Thesis 2017| 1. The AI system’s lack of understanding of human emotions impede an effective communication between the system and the human interactants. Emotions take a big part in communication as they allow humans to empathize and understand one another. 2. Explore validity of using the three-dimension emotion model as opposed to the naive polarity model in predicting the sentiment of given text data. 3. Use the three-dimension emotion model, namely the VAD vectors, and train emotion embeddings. 4. The visualization showed the lack of context generalization in emotion embedding|
|[Assessing State-of-the-Art Sentiment Models on State-of-the-Art Sentiment Datasets](https://arxiv.org/pdf/1709.04219)|WASSA 2017| Compare several sentiment analysis models on six different benchmarks, which belong to different domains and additionally have different levels of granularity (binary, 3-class, 4-class and 5-class).|
|[# BB_twtr at SemEval-2017 Task 4: Twitter Sentiment Analysis with CNNs and LSTMs](https://arxiv.org/pdf/1704.06125)|SemEval 2017| 1. Describe the attempt at producing a state-of-the-art Twitter sentiment classifier using Convolutional Neural Networks (CNNs) and Long Short Term Memory (LSTMs) networks. 2. The proposed system leverages a large amount of unlabeled data to pre-train word embeddings. 3. Then the authors use a subset of the unlabeled data to fine tune the embeddings using distant supervision. 4. Top performance is achieved by ensembling several CNNs and LSTMs|
|[DataStories at SemEval-2017 Task 4: Deep LSTM with Attention for Message-level and Topic-based Sentiment Analysis](http://aclweb.org/anthology/S17-2126)|SemEval 2017| 1. Propose Long Short-Term Memory (LSTM) networks augmented with two kinds of attention mechanisms, on top of word embeddings pre-trained on a big collection of Twitter messages. 2. Present a text processing tool suitable for social network messages, which performs tokenization, word normalization, segmentation and spell correction.|
|[Learning to Generate Reviews and Discovering Sentiment](https://arxiv.org/pdf/1704.01444)|Arxiv 2017| Find a single unit which performs sentiment analysis in byte-level recurrent language models.|
|[A Helping Hand: Transfer Learning for Deep Sentiment Analysis](http://www.aclweb.org/anthology/P18-1235)|ACL 2018| 1. Present an approach to feed generic cues into the training process of such networks, leading to better generalization abilities given limited training data. 2. Propose to induce sentiment embeddings via supervision on extrinsic data, which are then fed into the model via a dedicated memorybased component|
|[Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs](https://arxiv.org/pdf/1801.05453)|ICLR 2018| 1. Introduce contextual decomposition (CD), an interpretation algorithm for analysing individual predictions made by standard LSTMs, without any changes to the underlying model. 2. By decomposing the output of a LSTM, CD captures the contributions of combinations of words or variables to the final prediction of an LSTM.|
|[Emotion Recognition on Twitter: Comparative Study and Training a Unison Model](https://ieeexplore-ieee-org.ezlibproxy1.ntu.edu.sg/document/8295234)|IEEE TAC 2018| 1. Compare the performance of several word- and character-based recurrent and convolutional neural networks with the performance on bag-of-words and latent semantic indexing models. 2. Investigate the transferability of the final hidden state representations between different classifications of emotions, and whether it is possible to build a unison model for predicting all of them using a shared representation. 3. Show that recurrent neural networks, especially character-based ones, can improve over bag-of-words and latent semantic indexing models|
|[SeerNet at SemEval-2018 Task 1: Domain Adaptation for Affect in Tweets](https://arxiv.org/pdf/1804.06137)|SemEval 2018| The proposed system performs domain adaptation of 4 different models and creates an ensemble to give the final prediction|
|[A Sentiment-and-Semantics-Based Approach for Emotion Detection in Textual Conversations](https://arxiv.org/pdf/1707.06996)|Arxiv 2018| 1. Propose a novel approach to detect emotions like happy, sad or angry in textual conversations using an LSTM based Deep Learning model. 2. Combine both semantic and sentiment based embeddings|
|[DialogueRNN: An Attentive RNN for Emotion Detection in Conversations](https://arxiv.org/pdf/1811.00405)|AAAI 2019|Introduce a new method based on recurrent neural networks that keeps track of the individual party states throughout the conversation and uses this information for emotion classification|

[Back to index](../README.md)

<!--stackedit_data:
eyJoaXN0b3J5IjpbMTI2MTA5NTc5NywtOTkzOTI2MTI3LDc1OT
c5NzIzMCw3NjQwODI4NzZdfQ==
-->